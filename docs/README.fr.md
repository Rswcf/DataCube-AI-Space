<div align="center">

# ğŸ§Š Data Cube AI

### Votre actualitÃ© IA quotidienne, curÃ©e par l'IA.

**AgrÃ©gateur d'actualitÃ©s IA bilingue (DE/EN)** qui sÃ©lectionne les avancÃ©es technologiques, les investissements, les conseils pratiques et les vidÃ©os YouTube â€” alimentÃ© par un pipeline LLM en 4 Ã©tapes.

[![Licence MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![DÃ©mo en ligne](https://img.shields.io/badge/demo-datacubeai.space-brightgreen)](https://www.datacubeai.space)
[![CI](https://img.shields.io/github/actions/workflow/status/Rswcf/DataCube-AI-Space/ci.yml?label=CI)](https://github.com/Rswcf/DataCube-AI-Space/actions)

[English](../README.md) | [ç®€ä½“ä¸­æ–‡](README.zh-CN.md) | [Deutsch](README.de.md) | **FranÃ§ais** | [EspaÃ±ol](README.es.md) | [PortuguÃªs](README.pt-BR.md) | [æ—¥æœ¬èª](README.ja.md) | [í•œêµ­ì–´](README.ko.md)

</div>

---

## Qu'est-ce que Data Cube AI ?

Data Cube AI collecte, classe et rÃ©sume automatiquement les actualitÃ©s IA provenant de **22 flux RSS**, **Hacker News** et **YouTube** â€” puis les prÃ©sente dans une interface bilingue (allemand/anglais) claire avec des vues quotidiennes et hebdomadaires.

**Accessible sur [datacubeai.space](https://www.datacubeai.space)** â€” aucune connexion requise.

<div align="center">

https://github.com/user-attachments/assets/9dddaaed-e473-4350-97de-0346cacb6660

</div>

## FonctionnalitÃ©s

- **Fil Tech** â€” AvancÃ©es IA/ML avec vidÃ©os YouTube intÃ©grÃ©es et Ã©valuations d'impact
- **Suivi des investissements** â€” LevÃ©es de fonds primaires, donnÃ©es du marchÃ© secondaire (cours boursiers en temps rÃ©el via Polygon.io) et fusions-acquisitions
- **Conseils pratiques** â€” SÃ©lection provenant de 14 communautÃ©s Reddit et de blogs d'experts
- **Bilingue** â€” Chaque article en allemand et en anglais
- **Quotidien + Hebdomadaire** â€” Collecte quotidienne automatisÃ©e avec vues rÃ©capitulatives hebdomadaires
- **Chat IA** â€” Posez des questions sur les actualitÃ©s IA de la semaine en cours
- **Rapports IA** â€” GÃ©nÃ©ration de rapports en streaming en un clic, avec export en Word, HTML, Markdown, texte brut ou JSON
- **OptimisÃ© SEO/GEO** â€” Pages SSR, donnÃ©es structurÃ©es JSON-LD, flux Atom, llms.txt, sitemap
- **Accessible** â€” Conforme WCAG : cibles tactiles de 44px, focus-visible, ARIA, prefers-reduced-motion, liens d'Ã©vitement
- **Mobile-First** â€” Viewport dynamique, zones de sÃ©curitÃ© (safe area insets), navigation optimisÃ©e pour le tactile, verrouillage du dÃ©filement sur les overlays

## Architecture

```
Frontend (Vercel)                    Backend (Railway)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js 16         â”‚    REST     â”‚  FastAPI + PostgreSQL        â”‚
â”‚  React 19           â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                              â”‚
â”‚  Tailwind CSS 4     â”‚    API      â”‚  Pipeline en 4 Ã©tapes :      â”‚
â”‚  Shadcn/ui          â”‚             â”‚  1. Fetch (RSS, HN, YouTube) â”‚
â”‚                     â”‚             â”‚  2. Classify (LLM)           â”‚
â”‚  Pages :            â”‚             â”‚  3. Process (LLM, parallel)  â”‚
â”‚  â€¢ Fil Tech         â”‚             â”‚  4. Save to PostgreSQL       â”‚
â”‚  â€¢ Fil Investissementâ”‚            â”‚                              â”‚
â”‚  â€¢ Fil Conseils     â”‚             â”‚  Sources de donnÃ©es :        â”‚
â”‚  â€¢ Chat IA          â”‚             â”‚  â€¢ 22 flux RSS               â”‚
â”‚  â€¢ Rapports IA      â”‚             â”‚  â€¢ Hacker News (Algolia)     â”‚
â”‚  â€¢ Pages SSR        â”‚             â”‚  â€¢ YouTube Data API v3       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## DÃ©marrage rapide

### PrÃ©requis

- Node.js 18+
- Python 3.11+
- PostgreSQL
- ClÃ©s API : [OpenRouter](https://openrouter.ai), [YouTube Data API v3](https://console.cloud.google.com), [Polygon.io](https://polygon.io) (optionnel, pour les cours boursiers en temps rÃ©el)

### Frontend

```bash
cd ai-information-hub
cp .env.example .env.local    # Ajoutez vos clÃ©s API
npm install
npm run dev                   # http://localhost:3000
```

### Backend

```bash
cd ai-hub-backend
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env          # Ajoutez vos clÃ©s API

python -m scripts.init_db --migrate-all
uvicorn app.main:app --reload # http://localhost:8000/docs
```

### Lancer la collecte de donnÃ©es

```bash
# Collecte quotidienne (aujourd'hui)
python -m scripts.daily_collect

# Collecte hebdomadaire (semaine en cours)
python -m scripts.weekly_collect

# Date/semaine spÃ©cifique
python -m scripts.daily_collect --date 2026-02-07
python -m scripts.weekly_collect --week 2026-kw06
```

## Stack technique

| Couche | Technologie |
|--------|------------|
| **Frontend** | Next.js 16, React 19, Tailwind CSS 4, Shadcn/ui, TypeScript |
| **Backend** | FastAPI, SQLAlchemy, Alembic, PostgreSQL |
| **Classification LLM** | GLM-4.5-Air (OpenRouter, niveau gratuit) |
| **Traitement LLM** | DeepSeek V3.2 (OpenRouter) |
| **Chat et rapports** | Aurora Alpha (OpenRouter) |
| **DonnÃ©es boursiÃ¨res** | API Polygon.io |
| **HÃ©bergement** | Vercel (frontend), Railway (backend + BDD + cron) |
| **Design** | Police Newsreader, logo cube isomÃ©trique, accents de couleur par section, animations Ã©chelonnÃ©es |

## Pipeline de donnÃ©es

Le backend traite les actualitÃ©s via un pipeline en 4 Ã©tapes :

| Ã‰tape | Description | RÃ©sultat |
|-------|------------|----------|
| **1. Collecte** | RÃ©cupÃ©ration depuis RSS, Hacker News, YouTube ; filtrage par limites de pÃ©riode | ~210 Ã©lÃ©ments bruts |
| **2. Classification** | Le LLM classe en tech/investissement/conseils (les sources de conseils sautent cette Ã©tape) | Pool catÃ©gorisÃ© |
| **3. Traitement** | Traitement LLM en parallÃ¨le : gÃ©nÃ©ration de rÃ©sumÃ©s bilingues, extraction d'entitÃ©s | 30 tech + 21 investissement + 15 conseils + 5 vidÃ©os |
| **4. Sauvegarde** | Stockage dans PostgreSQL, intÃ©gration des vidÃ©os dans le fil tech | Enregistrements en base |

Les collectes quotidiennes produisent des volumes rÃ©duits (10 tech, 5 investissement, 5 conseils, 2 vidÃ©os).

## RÃ©fÃ©rence API

| Point d'accÃ¨s | MÃ©thode | Description |
|---------------|---------|-------------|
| `/api/weeks` | GET | Lister les pÃ©riodes (semaines avec jours imbriquÃ©s) |
| `/api/tech/{periodId}` | GET | Fil tech avec vidÃ©os intÃ©grÃ©es |
| `/api/investment/{periodId}` | GET | DonnÃ©es primaire/secondaire/fusions-acquisitions |
| `/api/tips/{periodId}` | GET | Conseils sÃ©lectionnÃ©s |
| `/api/videos/{periodId}` | GET | RÃ©sumÃ©s de vidÃ©os YouTube |
| `/api/stock/{ticker}` | GET | DonnÃ©es boursiÃ¨res en temps rÃ©el |
| `/api/stock/batch/?tickers=AAPL,NVDA` | GET | DonnÃ©es boursiÃ¨res par lot |
| `/api/admin/collect` | POST | DÃ©clencher une collecte complÃ¨te |

Identifiants de pÃ©riode : quotidien `YYYY-MM-DD` ou hebdomadaire `YYYY-kwWW`

La documentation complÃ¨te de l'API est disponible sur `/docs` (Swagger UI) lorsque le backend est en cours d'exÃ©cution.

## Variables d'environnement

### Frontend (`ai-information-hub/.env.local`)

```bash
OPENROUTER_API_KEY=sk-or-v1-...     # Pour les fonctionnalitÃ©s de chat et de rapports
YOUTUBE_API_KEY=AIza...              # Pour les mÃ©tadonnÃ©es vidÃ©o
NEXT_PUBLIC_API_URL=http://localhost:8000/api  # URL du backend
```

### Backend (`ai-hub-backend/.env`)

```bash
DATABASE_URL=postgresql://user:pass@localhost:5432/aihub
OPENROUTER_API_KEY=sk-or-v1-...     # Pour la classification et le traitement LLM
YOUTUBE_API_KEY=AIza...              # Pour la rÃ©cupÃ©ration de vidÃ©os
POLYGON_API_KEY=...                  # Optionnel : donnÃ©es boursiÃ¨res en temps rÃ©el
ADMIN_API_KEY=your-secret-key       # ProtÃ¨ge les points d'accÃ¨s d'administration
CORS_ORIGINS=["http://localhost:3000"]
```

## DÃ©ploiement

### Frontend â†’ Vercel

```bash
cd ai-information-hub
vercel --prod
```

Configurez les variables d'environnement dans le tableau de bord Vercel. DÃ©ploiement automatique lors d'un push sur `main`.

### Backend â†’ Railway

```bash
cd ai-hub-backend
railway up
```

Railway applique automatiquement les migrations Alembic au dÃ©marrage. Configurez une tÃ¢che cron pour la collecte quotidienne Ã  22h00 UTC.

## Structure du projet

```
DataCube-AI-Space/
â”œâ”€â”€ ai-information-hub/          # Frontend (Next.js)
â”‚   â”œâ”€â”€ app/                     # Pages + routes API
â”‚   â”‚   â”œâ”€â”€ api/chat/            # Point d'accÃ¨s du chat IA
â”‚   â”‚   â”œâ”€â”€ api/report/          # GÃ©nÃ©rateur de rapports IA
â”‚   â”‚   â”œâ”€â”€ [lang]/week/         # Pages SSR par semaine (SEO)
â”‚   â”‚   â””â”€â”€ feed.xml/            # Flux Atom 1.0
â”‚   â”œâ”€â”€ components/              # Composants React
â”‚   â”‚   â”œâ”€â”€ feeds/               # Fils Tech, Investissement, Conseils
â”‚   â”‚   â””â”€â”€ video-embed.tsx      # Lecteur YouTube
â”‚   â”œâ”€â”€ lib/                     # Utilitaires, types, client API
â”‚   â””â”€â”€ middleware.ts            # Contournement des crawlers + portail d'accueil
â”‚
â”œâ”€â”€ ai-hub-backend/              # Backend (FastAPI)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/              # ModÃ¨les SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ routers/             # Points d'accÃ¨s API
â”‚   â”‚   â””â”€â”€ services/            # Logique mÃ©tier
â”‚   â”‚       â”œâ”€â”€ collector.py     # Pipeline en 4 Ã©tapes
â”‚   â”‚       â”œâ”€â”€ llm_processor.py # Approche LLM Ã  deux modÃ¨les
â”‚   â”‚       â””â”€â”€ youtube_fetcher.py
â”‚   â”œâ”€â”€ alembic/                 # Migrations BDD
â”‚   â”œâ”€â”€ scripts/                 # Outils CLI (collecte quotidienne/hebdomadaire)
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ docs/                        # README traduits
â””â”€â”€ LICENSE
```

## Contribuer

Les contributions sont les bienvenues ! Voici comment dÃ©marrer :

1. Forkez le dÃ©pÃ´t
2. CrÃ©ez une branche de fonctionnalitÃ© (`git checkout -b feature/fonctionnalite-geniale`)
3. Validez vos modifications (`git commit -m 'Add fonctionnalite-geniale'`)
4. Poussez la branche (`git push origin feature/fonctionnalite-geniale`)
5. Ouvrez une Pull Request

Assurez-vous que votre code passe les vÃ©rifications CI :
- **Frontend** : `tsc --noEmit` + `next build`
- **Backend** : `ruff check`

## Licence

Ce projet est sous licence MIT â€” voir le fichier [LICENSE](../LICENSE) pour plus de dÃ©tails.

---

<div align="center">

**[DÃ©mo en ligne](https://www.datacubeai.space)** Â· **[Signaler un bug](https://github.com/Rswcf/DataCube-AI-Space/issues)** Â· **[Demander une fonctionnalitÃ©](https://github.com/Rswcf/DataCube-AI-Space/issues)**

Si vous trouvez ce projet utile, n'hÃ©sitez pas Ã  lui attribuer une Ã©toile !

</div>
